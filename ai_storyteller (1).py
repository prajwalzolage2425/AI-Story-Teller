# -*- coding: utf-8 -*-
"""AI Storyteller.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YBC9J9BaPPn2mdjcaccv9PLPoHGlM46h
"""

# Commented out IPython magic to ensure Python compatibility.
# @title
# %env GEMINI_API-KEY=AIzaSyDekFDtJyWWKxLgtTQ207BA-bWa2qoENeM

!pip install -q transformers pillow google-generativeai

from google import genai
import os
client = genai.Client(api_key=os.getenv("GEMINI_API-KEY"))

if "GEMINI_API-KEY" not in os.environ:
  print("Please set your Gemini API key in the environment variable GEMINI_API-KEY")
else:
  client=genai.Client(api_key=os.getenv("GEMINI_API-KEY"))
  MODEL="gemini-2.5-flash"

prompt=input("Enter your story prompt and press enter:\n")
if prompt.strip()=="":
  print("No prompt entered, Exiting")
else:
  print(f"Generating story with prompt: {prompt}")
  print("It may take few second")
  try:
    resp=client.models.generate_content(model=MODEL,contents=[prompt])
    print("\n----Generted Story-------\n")
    print(resp.text)
  except Exception as e:
    print(f"Error ocurred while generating story: {e}")

!pip install -q transformers pillow google-generativeai timm

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
from google import genai
import os
import io

if "GEMINI_API-KEY" not in os.environ:
  print("Please set your Gemini API key in the environment variable GEMINI_API-KEY")
else:
  client=genai.Client(api_key=os.getenv("GEMINI_API-KEY"))
  MODEL="gemini-2.5-flash"

processor=BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model=BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

from google.colab import files
uploaded=files.upload()

for fn in uploaded.keys():
  image=Image.open(fn).convert("RGB")
  display(image)

inputs=processor(images=image,return_tensors="pt")
out=model.generate(**inputs)

captions=processor.decode(out[0],
skip_special_tokens=True)

print("Caption generated by BLIP: ")
print(captions)

story_prompt=(f"write a short(around 200-500 words) based on this scene description: {captions}")
print(story_prompt)

print("Sending this to Gemini. \n")

response=client.models.generate_content(model=MODEL,contents=[story_prompt])
story=response.text
print("\n----Generated Story----\n")
print(story)

with open("generated_story.txt","w") as f:
  f.write(story)

  from google.colab import files
  files.download("generated_story.txt")

!pip install -q ipywidgets

from google.colab import files
from PIL import Image
import io

uploaded=files.upload()

images=[]
image_names=[]

for name, file in uploaded.items():
  image=Image.open(io.BytesIO(file)).convert('RGB') # Fix: call convert after opening the image
  image_names.append(name)
  images.append(image)
  display(image)

from transformers import BlipProcessor, BlipForConditionalGeneration

processor=BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
model=BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

captions=[]

for img in images:
  inputs=processor(images=img,return_tensors="pt")
  out=model.generate(**inputs, max_new_tokens=30)
  caption=processor.decode(out[0],skip_special_tokens=True)
  captions.append(caption)

print("Captions generated from images:")
for i, caption in enumerate(captions):
  print(f"{image_names[i]}: {caption}")

import ipywidgets as widgets
from IPython.display import display , clear_output

tone_dropdown=widgets.Dropdown(
    options=["whimsical","adventurous","suspenseful","romantic","Sci-fi","mystery"],
    value="adventurous",
    description="Select Tone:"
)

length_dropdown=widgets.Dropdown(
    options=["Short(100-200 words)",
            "Medium(300-400 words)",
            "Long(400-600 words)"],
    value="Medium(300-400 words)",
    description="Select Length:"
)

generate_button=widgets.Button(description="Generate Story")
output_box=widgets.Output()

display(tone_dropdown,length_dropdown,generate_button,output_box)

def on_generate_clicked(b):
  with output_box:
    clear_output()

    tone=tone_dropdown.value
    length_map={
        "Short(100-200 words)":"100-200 words",
        "Medium(300-400 words)":"300-400 words",
        "Long(400-600 words)":"400-600 words"
    }
    length=length_map[length_dropdown.value]

    captions_prompt="\n".join([f"- {c}" for c in captions])

    outline_prompt=(
        f"Using the following scene description, create a 3-Chapter story outline. "
        f"Each chapter should have a tittle and a short summary.\n\n"
        f"{captions_prompt}\n\nOutline:"
    )

    try:
      outline_response=client.models.generate_content(model=MODEL,contents=[outline_prompt])
      outline_text=outline_response.text
      print("----Generated Story Outline----\n")
      print(outline_text)

      full_story=""
      for i in range(1,4):
        chapter_prompt=(
            f"Using outline below, write Chapter {i} in a {tone} tone."
            f"Make it {length}. Add vivid details, good pacing, and consistent chapters.\n\n"
            f"{outline_text}\n\nChapter {i}:"
        )
        chapter_response=client.models.generate_content(model=MODEL,contents=[chapter_prompt])
        chapter_text=chapter_response.text
        print(chapter_text)
        full_story+=f"\n\nChapter {i}:\n{chapter_text}"

      with open("multi_image_story.txt","w") as f:
        f.write(full_story)
      print("\n Story saved as multi_image_story.txt")

      from google.colab import files
      files.download("multi_image_story.txt")

    except Exception as e:
      print(f"Error occurred while generating story: {e}")

generate_button.on_click(on_generate_clicked)

!pip install -q gtts reportlab

# You can paste your story here or load from file
story_text="""
 Chapter 1: The Canvas and the Companion

*   **Summary:** Evelyn, an artist struggling with a creative block, is tasked with restoring a peculiar, vibrant painting of a man in a yellow outfit with a striking red scarf. The painting, unlike any she's encountered, seems to subtly shift before her eyes. Days later, her reality takes a surreal turn when she finds a full-sized giraffe casually waiting for her in her apartment building's parking lot, as if an old friend. She names him Sunny. Shortly after, a cryptic invitation arrives, requesting her presence before a mysterious 'Curiosity Committee' at an undisclosed location, hinting at a connection to her recent peculiar experiences.

### Chapter 2: The Enigmatic Audience

*   **Summary:** Evelyn, accompanied by Sunny (who mysteriously seems to appear and disappear as needed), attends the 'Committee' meeting. Three enigmatic figures sit on a single chair behind a shimmering pink curtain, their faces obscured. They speak in riddles, revealing that the man in the painting is a legendary 'Dream Weaver' and Evelyn, with her unique perception that allows her to see creatures like Sunny, is crucial to their quest. They task her with finding a lost 'Dream Key,' believed to be hidden within the Dream Weaver's forgotten memories, possibly linked to the red scarf. Overwhelmed but intrigued, Evelyn finds a moment of solace in a vivid recurring childhood memory: her dog, Skipper, joyfully playing with a frisbee on a vast, peaceful beach – a memory that feels suddenly more real than her current reality.

### Chapter 3: The Beach of Forgotten Dreams

*   **Summary:** Following a realization about the 'red scarf' symbolizing courage and the 'yellow outfit' representing joy in freedom, Evelyn understands that her beach memory isn't just a memory, but a fragment of the Dream Weaver's world, a clue to the 'Dream Key.' With Sunny as her guide, she travels to the secluded beach from her vision. There, a golden retriever, strikingly similar to her childhood dog Skipper, stands waiting with a frisbee. The dog leads her to a hidden spot where the 'Dream Key' is revealed. As Evelyn touches it, the painting's colors intensify, and she comprehends the Dream Weaver's message: to embrace the surreal, unlock her own imagination, and realize that the world around her is a canvas waiting for her to paint her own extraordinary reality. Her journey of creation has truly begun.
Chapter 1: The Canvas and the Companion

Evelyn, an artist whose palette had run dry, found herself staring at a painting unlike any she’d ever encountered. The vibrant portrait of a man in a blinding yellow outfit and a strikingly red scarf pulsed with a life that wasn't merely pigment. His painted gaze, she swore, subtly shifted whenever she turned away, a silent challenge to her perception. Days later, reality truly fractured. Descending to her apartment's parking lot, a magnificent, full-sized giraffe stood waiting, its soft eyes regarding her with the warmth of an old friend. She named him Sunny. Before the wonder could settle, a crisp, unmarked invitation materialized on her easel, demanding her presence before the mysterious 'Curiosity Committee' at an undisclosed location. Her world, once a blank canvas, was suddenly bursting with impossible colors and whispered adventures, and Evelyn, brush in hand, felt an unfamiliar tremor of excitement.
Evelyn stepped into an antechamber bathed in an otherworldly glow, Sunny's massive form shimmering into existence beside her with a silent, familiar grace. Before them, a shimmering pink curtain, alive with its own light, concealed three enigmatic figures perched precariously on a single, oversized chair. "The world is but a dream, and you, the rare artist who can see its threads, are crucial," a voice, a blend of ancient echoes, declared from behind the veil.

They revealed the man in her painting to be a fabled Dream Weaver, and tasked her with a perilous quest: to unearth his lost 'Dream Key,' believed to be woven into forgotten memories and perhaps symbolized by his vibrant red scarf. The weight of their riddles pressed in, but Evelyn’s mind found an immediate, vivid escape – Skipper, her childhood dog, a joyous golden streak against the endless blue of a sun-kissed beach, forever chasing a bright red frisbee. It felt less like a memory, more like a beckoning.
Evelyn gasped, the realization hitting her with the force of a crashing wave. The scarlet scarf wasn't mere fabric; it was a symbol of **courage**. The Dream Weaver's joyous yellow outfit, a beacon of **freedom**. Her beach memory, Skipper, the frisbee – it wasn't just her past, but a fragment of the Weaver's world, a tangible clue to the lost Dream Key!

Sunny, ever the silent, majestic guide, appeared at her side, his vast eyes gleaming with knowing anticipation. With a resolute breath, Evelyn followed, her heart pounding with a thrilling mixture of apprehension and exhilaration. The air around them shifted, thick with the unmistakable tang of salt and sun. In a blink, they stood upon the vast, echoing sands of her childhood dream, the very beach she'd cherished.

There, silhouetted against the sparkling horizon, stood a golden retriever, strikingly like Skipper, a well-worn frisbee clutched gently in its mouth. Wagging its tail furiously, the dog dropped the frisbee, then nudged a weathered piece of driftwood. Beneath it, gleaming with an ethereal, shifting light, lay the Dream Key – an intricate, silver compass etched with forgotten symbols.

As Evelyn’s fingers brushed the cool metal, a jolt of understanding coursed through her. Back in her studio, the Dream Weaver’s painting exploded with incandescent vibrancy, its colors now thrumming with untold stories. She understood. The Weaver’s message was clear: embrace the wild, the impossible, the surreal. This world was her canvas, and with imagination as her brush, she was ready to paint her own extraordinary reality. Her true journey of creation had just begun.
"""

from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas

def export_pdf(text, filename="story.pdf"):
    c=canvas.Canvas(filename,pagesize=letter)
    width,height=letter
    text_object=c.beginText(40,height-40)
    text_object.setFont("Helvetica",12)

    for line in text.split("\n"):
        for subline in[line[i:i+90]for i in range(0, len(line),90)]:
            text_object.textLine(subline)
    c.drawText(text_object)
    c.save()

export_pdf(story_text)


from google.colab import files
files.download("story.pdf")

from gtts import gTTS
from IPython.display import Audio , display
from google.colab import files

voices ={
    "Default English (US Female)": {"lang": "en","tld":"com"},
    "British Accent": {"lang": "en","tld":"co.uk"},
    "Australian Accent": {"lang": "en","tld":"com.au"},
    "Indian Accent": {"lang": "en","tld":"co.in"},
    "Slow Reading Voice":{"lang":"en","tld":"com","slow":True}
}

for label,options in voices.items():
  print(f"Generating Audio:{label}")

  tts=gTTS(
      text=story_text,
      lang=options["lang"],
      tld=options.get("tld","com"),
      slow=options.get("slow",False)
  )

  filename= f"{label.replace(' ','-').lower()}.mp3"

  tts.save(filename)

  display(Audio(filename=filename, autoplay=True))

  files.download(filename)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_streamlit_story.py
# import streamlit as st
# from PIL import Image
# import io, requests, os
# import textwrap
# from gtts import gTTS
# from transformers import BlipProcessor, BlipForConditionalGeneration
# from reportlab.pdfgen import canvas
# from reportlab.lib.pagesizes import A4
# from reportlab.lib.utils import ImageReader
# from pyngrok import ngrok
# import tempfile
# import google.generativeai as genai
# import torch
# import time
# 
# #Authentication
# NGROK_AUTH_TOKEN ="33VfB9afk2bE09xDzpAPLrc2wPO_479KUzZVbcWncSyXtD8MC"
# BACKGROUND_IMAGE_URL="https://i.postimg.cc/RVRP5v6d/web-back.png"
# GEMINI_API_KEY ="AIzaSyDekFDtJyWWKxLgtTQ207BA-bWa2qoENcM"
# 
# 
# st.set_page_config(page_title="StoryTeller", layout="wide")
# 
# #Streamlit Page Setup/Style
# st.markdown(
#    f"""
#    <style>
#    .stApp {{
#        background-image: url("{BACKGROUND_IMAGE_URL}");
#        background-size: cover;
#        background-attachment: fixed;
#    }}
#    section[data-testid="stSidebar"] {{
#        background: rgba(0,0,0,0.3);
#        backdrop-filter: blur(10px);
#        border-radius: 12px;
#        padding: 10px;
#    }}
#    div[data-testid="stFileUploader"] {{
#        background: rgba(255,255,255,0.2);
#        border-radius: 10px;
#        padding: 10px;
#    }}
#    html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, li, input, textarea {{
#        color: #93A8AC !important;
#    }}
#    .stButton>button, .stDownloadButton>button {{
#        color: black !important;
#        border-color: #93A8AC;
#    }}
#    </style>
#    """,
#    unsafe_allow_html=True
# )
# 
# 
# 
# 
# with st.sidebar:
#    tone = st.selectbox("Tone", ["Adventurous", "Whimsical", "Romantic", "Mysterious", "Humorous", "Calm"])
#    length_label = st.selectbox("Length", ["Short (200-300 words)", "Medium (300-600 words)", "Long (600-1000 words)"])
#    start_ngrok = st.checkbox("Start ngrok tunnel")
#    if start_ngrok:
#        ngrok.set_auth_token(NGROK_AUTH_TOKEN)
#        url = ngrok.connect(8501)
#        st.success(f"Public URL: {url}")
# 
# uploaded_images = st.file_uploader("Upload multiple images", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
# 
# #caption Model
# @st.cache_resource
# def load_models():
#    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
#    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large").to("cuda" if torch.cuda.is_available() else "cpu")
#    return processor, model
# 
# processor, blip_model = load_models()
# 
# ##config gemini
# genai.configure(api_key=GEMINI_API_KEY)
# 
# @st.cache_resource
# def load_gemini_model():
#    return genai.GenerativeModel(model_name="models/gemini-2.5-flash")
# 
# gemini_model = load_gemini_model()
# 
# 
# #captioning the image
# def get_captions(images):
#   captions=[]
#   for img in images:
#     if img.mode !="RGB":
#       img=img.convert("RGB")
#     inputs=processor(images=img, return_tensors="pt").to(blip_model.device) # Corrected line
#     out=blip_model.generate(**inputs)
#     caption=processor.decode(out[0], skip_special_tokens=True)
#     captions.append(caption)
#   return captions
# 
# def generate_story(captions, tone, length_label):
#    length_map = {
#        "Short (200-300 words)": (200, 300, 800),
#        "Medium (300-600 words)": (300, 600, 1200),
#        "Long (600-1000 words)": (600, 1000, 1600)
#    }
#    min_words, max_words, max_tokens = length_map.get(length_label, (300, 600, 1200))
#    prompt = (
#     f"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\n\n"
#     + "\n".join([f"- {cap}" for cap in captions])
#     + f"\n\nThe story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle, and end."
#     + f"\nMake it approximately between {min_words} and {max_words} words long."
# )
#    # Configure safety settings - Adjust thresholds as needed
#    safety_settings = [
#        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
#        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
#        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
#        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
#    ]
# 
#    for attempt in range(3): # Add retry mechanism
#        try:
#            response = gemini_model.generate_content(
#                contents=prompt,
#                generation_config=genai.GenerationConfig(
#                    temperature=0.9,
#                    top_p=0.95,
#                    max_output_tokens=max_tokens
#                ),
#                safety_settings=safety_settings # Apply safety settings
#            )
#            # Check if response has text
#            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
#                return response.text.strip()
#            else:
#                # Log finish reason for debugging
#                finish_reason = response.candidates[0].finish_reason if response.candidates else 'unknown'
#                st.warning(f"Story generation failed (attempt {attempt + 1}): Model returned no valid parts. Finish reason: {finish_reason}. Retrying...")
#                time.sleep(2) # Wait before retrying
#        except Exception as e:
#            st.warning(f"Story generation failed (attempt {attempt + 1}): {e}. Retrying...")
#            time.sleep(2) # Wait before retrying
# 
#    return "❌ Failed to generate story after multiple attempts. This could be due to safety filters. Please try a different prompt or tone." # Return error message after retries
# 
# #pdf generation
# def create_pdf(story_text, images):
#    buffer = io.BytesIO()
#    c = canvas.Canvas(buffer, pagesize=A4)
#    w, h = A4
#    try:
#        response = requests.get(BACKGROUND_IMAGE_URL, stream=True)
#        response.raise_for_status() # Raise an exception for bad status codes
#        bg_img = Image.open(response.raw).convert("RGB")
#        bg = ImageReader(bg_img)
#        c.drawImage(bg, 0, 0, width=w, height=h)
#    except requests.exceptions.RequestException as e:
#        st.warning(f"Could not load background image for PDF: {e}")
#        pass # Continue creating PDF without background image
# 
#    c.setFont("Helvetica-Bold", 16)
#    c.drawString(50, h - 50, "Generated Story")
#    text = textwrap.wrap(story_text, 100)
#    y = h - 80
#    for line in text:
#        if y < 80:
#            c.showPage()
#            y = h - 80
#        c.drawString(50, y, line)
#        y -= 15
#    if images:
#        c.showPage()
#        c.setFont("Helvetica-Bold", 16)
#        c.drawString(50, h - 50, "Uploaded Images")
#        x, y = 50, h - 150
#        for img in images:
#            img.thumbnail((200, 200))
#            c.drawImage(ImageReader(img), x, y, width=img.width, height=img.height)
#            x += 220
#            if x > w - 200:
#                x = 50
#                y -= 220
#    c.save()
#    buffer.seek(0)
#    return buffer
# 
# #Audio generation
# def create_audio(story):
#    audio_bytes = io.BytesIO()
#    tts = gTTS(story)
#    tts.write_to_fp(audio_bytes)
#    audio_bytes.seek(0)
#    return audio_bytes
# 
# #Processing part
# if st.button("Generate Story") and uploaded_images:
#    pil_images = [Image.open(img) for img in uploaded_images]
#    with st.spinner("Generating captions..."):
#        captions = get_captions(pil_images)
#        for i, cap in enumerate(captions):
#            st.write(f"**Image {i+1}**: {cap}")
# 
#    with st.spinner("Generating story..."):
#        story = generate_story(captions, tone, length_label)
#        st.success("Story generated!")
#        st.write(story)
# 
#    with st.spinner("Creating PDF..."):
#        pdf_file = create_pdf(story, pil_images)
#        st.download_button("📄 Download Story as PDF", data=pdf_file, file_name="story.pdf", mime="application/pdf")
# 
#    with st.spinner("Creating Audio..."):
#        audio = create_audio(story)
#        st.audio(audio)
#        st.download_button("🔊 Download Story as MP3", data=audio, file_name="story.mp3", mime="audio/mpeg")
# elif not uploaded_images:
#    st.warning("Upload at least one image to begin.")

ngrok.kill()

!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow


!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &

from pyngrok import ngrok
# Replace "Enter your Auth code here" with your actual ngrok authentication token
ngrok.set_auth_token("33VfB9afk2bE09xDzpAPLrc2wPO_479KUzZVbcWncSyXtD8MC")
url = ngrok.connect(8501)
print("Public URL:", url)